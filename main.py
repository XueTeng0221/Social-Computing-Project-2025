# main.py

import torch
import pandas as pd
import os
import argparse
from torch_geometric.data import HeteroData
from torch_geometric.data.storage import BaseStorage, GlobalStorage, NodeStorage, EdgeStorage
from models import FraudDetector
from preprocessor import DataPreprocessor
from trainer import train_epoch, evaluate, FocalLoss

torch.serialization.add_safe_globals([
    HeteroData, BaseStorage, GlobalStorage, NodeStorage, EdgeStorage
])


def prepare_data(force_rebuild) -> HeteroData:
    """å‡†å¤‡å¹¶åŠ è½½å›¾æ•°æ®"""
    graph_path = 'data/processed/hetero_graph.pt'
    if os.path.exists(graph_path) and not force_rebuild:
        print("ğŸ“‚ åŠ è½½å·²æœ‰å›¾æ•°æ®...")
        data = torch.load(graph_path, weights_only=True)
    else:
        print("ğŸ”¨ æ„å»ºæ–°å›¾...")
        df_posts = pd.read_csv('data/raw/posts.csv')
        df_users = pd.read_csv('data/raw/users.csv')
        df_relations = pd.read_csv('data/raw/relations.csv')
        preprocessor = DataPreprocessor()
        data = preprocessor.build_graph(df_posts, df_users, df_relations)
        os.makedirs('data/processed', exist_ok=True)
        torch.save(data, graph_path)
        print(f"ğŸ’¾ å›¾å·²ä¿å­˜åˆ° {graph_path}")
    
    return data


def split_dataset(data, train_ratio=0.7, val_ratio=0.15):
    """åˆ’åˆ†è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†"""
    num_posts = data['post'].y.size(0)
    indices = torch.randperm(num_posts)
    train_size = int(train_ratio * num_posts)
    val_size = int(val_ratio * num_posts)
    train_idx = indices[:train_size]
    val_idx = indices[train_size:train_size + val_size]
    test_idx = indices[train_size + val_size:]
    data['post'].train_mask = torch.zeros(num_posts, dtype=torch.bool)
    data['post'].val_mask = torch.zeros(num_posts, dtype=torch.bool)
    data['post'].test_mask = torch.zeros(num_posts, dtype=torch.bool)
    data['post'].train_mask[train_idx] = True
    data['post'].val_mask[val_idx] = True
    data['post'].test_mask[test_idx] = True
    print(f"ğŸ“Š æ•°æ®é›†åˆ’åˆ†: Train {len(train_idx)} | Val {len(val_idx)} | Test {len(test_idx)}")
    return data


def main():
    argp = argparse.ArgumentParser(description="è®­ç»ƒå¼‚æ„å›¾è¯ˆéª—æ£€æµ‹æ¨¡å‹")
    argp.add_argument('--alpha', type=float, default=0.7, help='Focal Loss çš„ alpha å‚æ•°')
    argp.add_argument('--gamma', type=float, default=2.0, help='Focal Loss çš„ gamma å‚æ•°')
    argp.add_argument('--force_rebuild', action='store_true', help='å¼ºåˆ¶é‡å»ºå›¾æ•°æ®')
    argp.add_argument('--epochs', type=int, default=50, help='è®­ç»ƒçš„æœ€å¤§è½®æ•°')
    argp.add_argument('--patience', type=int, default=10, help='æ—©åœçš„è€å¿ƒå€¼')
    argp.add_argument('--lr', type=float, default=1e-4, help='å­¦ä¹ ç‡')
    argp.add_argument('--weight_decay', type=float, default=5e-4, help='æƒé‡è¡°å‡')
    argp.add_argument('--save-dir', type=str, default='models', help='æ¨¡å‹ä¿å­˜ç›®å½•')
    args = argp.parse_args()
    
    
    # 1. å‡†å¤‡æ•°æ®
    data = prepare_data(force_rebuild=args.force_rebuild)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")
    data = data.to(device)
    data = split_dataset(data)
    
    # 2. åˆå§‹åŒ–æ¨¡å‹
    model = FraudDetector(
        text_model_name='hfl/chinese-roberta-wwm-ext',
        hidden_channels=64,
        out_channels=1,
        metadata=data.metadata()
    ).to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)
    criterion = FocalLoss(alpha=args.alpha, gamma=args.gamma)
    
    # 3. è®­ç»ƒå¾ªç¯
    best_f1 = 0
    patience = args.patience
    patience_counter = 0
    for epoch in range(args.epochs):
        loss = train_epoch(model, data, optimizer, criterion)
        val_f1, val_auc = evaluate(model, data, data['post'].val_mask)
        print(f"Epoch {epoch+1:02d}: Loss {loss:.4f} | Val F1 {val_f1:.4f} | Val AUC {val_auc:.4f}")
        if val_f1 >= best_f1:
            best_f1 = val_f1
            torch.save(model.state_dict(), f'{args.save_dir}/best_model.pth')
            print(f"  âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (F1={best_f1:.4f})")
            patience_counter = 0
        else:
            patience_counter += 1
        
        if patience_counter >= patience:
            print(f"â¹ï¸  æ—©åœè§¦å‘ (patience={patience})")
            break
    
    print("\nğŸ‰ è®­ç»ƒå®Œæˆ!")
    
    # 4. æµ‹è¯•æœ€ä½³æ¨¡å‹
    model.load_state_dict(torch.load(f'{args.save_dir}/best_model.pth', weights_only=True))
    test_f1, test_auc = evaluate(model, data, data['post'].test_mask)
    print(f"\nğŸ¯ æµ‹è¯•é›†æ€§èƒ½: F1 {test_f1:.4f} | AUC {test_auc:.4f}")


if __name__ == "__main__":
    main()
